02/20/2018
Author: Michael Allen

Title: Exploratory Analysis & Some Statisitcal Concepts of Zillow Housing Dataset and a Seperate Web Scraping Exercise with the Website (http://livingwage.mit.edu/) for the Living Wage Calculator.


Sprint First Week:  - To write a script in R to read the CSV file containing Zillow Sales Price Dataset.  Then to use R to perform initial exporatory analysis and to utilize the filter within the R Studio program to assist with the analysis. To write a script which calculated Cross Tabulation, Kurtosis, and Skewness since these were concepts I did not understand.  There were various other concepts that I also was going to pursue and put into this R program, but towards the end of the first week it was decided to instead pursue the Webscaping project (for which I have never done) from livingwage.mit.edu. 


As a Technology Teacher I need to be able to take a new dataset and be able to do preliminary exploratory analysis to determine what trends/analysis is relatively quickly apparent - which will provide direction for further analysis.  In addition, though it had been discussed and implemented by others in class, I now see the application for and the ability to do basic Webscraping.  Much more to do on this however.  I hope to be able to use these concepts as I move further along in this program and also outside of this program after completion.


For the first week's project, set the proper working directory in R, read in the Zillow Housing Dataset, performed exploratory analysis, wrote a script to calculate some fields for Cross Tabulation, Kurtosis, and Skewness.

For the second weeks project, Webscraping of the Living Wage Calculator, in R read in 51 different html url's (50 of the US States and then one for the District of Columbia) which had the total of each States Average supposed Living Wage, Expenses, and Earnings by Occupation.  This only took almost 2000 lines of code to do...  I needed assistance along the way (Thanks Ben) and working with my partner for the week (Thanks Tori) to accomplish.   

Things I learned:

Since in reality only spent a little time on the first week's exploratory analysis and statistical concept applications, there is more to do in a future Sprint to complete this exercise in order to adequetely learn from it.  

For the second week, I am sure there is an unlimited amount of data out on the Internet that could be webscraped and analyzed in various ways to help assist in business decisions.  But for what I did, I learned NOT to do manual calculations over and over and over but to first perhaps do a few to get the gist of it, then do a build/find of a function to do it for you.  This is what I hope to accomplish in a future Sprint. 
  
